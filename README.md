# ROB538_Project
ROB538 Rover Domain Project

A common task in multiagent learning, especially in the field of robotics, is to move in coordination with other agents in order to sample points of interest (POI). The continuous rover domain tackles this problem by having stationary POIs and having rovers sample them by moving close to them. However, in many real life scenarios the POIs are not stationary. Examples include wildlife monitoring, search and rescue, and weather tracking. In this work, the continuous rover domain is extended by adding continuously moving POIs. Local, Global, and Difference reward structures for neuroevolutionary learning are tested and analyzed in highly dynamic environments with moving POIs. Additionally, the existing states of the rover domain, which consists of a set of sensors for sensing nearby POIs and a set of sensors for sensing nearby rovers, are extended by adding another sensor layer which gives information about the future position estimates for the POIs. Our results show that extending the states leads to faster learning even though the weight space for the neural network becomes more complex.
